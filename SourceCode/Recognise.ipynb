{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nothing(x):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_x, image_y = 64,64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "classifier = load_model('ASLModel.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "riginal = cv2.imread(\"5.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileEntry=[]\n",
    "for file in os.listdir(\"SampleGestures\"):\n",
    "    if file.endswith(\".png\"):\n",
    "    \tfileEntry.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgprocessing():\n",
    "    image_to_compare = cv2.imread(\"./SampleGestures/space.png\")\n",
    "    original = cv2.imread(\"1.png\")\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    kp_1, desc_1 = sift.detectAndCompute(original, None)\n",
    "    kp_2, desc_2 = sift.detectAndCompute(image_to_compare, None)\n",
    "   \n",
    "    index_params = dict(algorithm=0, trees=5)\n",
    "    search_params = dict()\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    \n",
    "    matches = flann.knnMatch(desc_1, desc_2, k=2)\n",
    "   \n",
    "    good_points = []\n",
    "    ratio = 0.6\n",
    "    for m, n in matches:\n",
    "        if m.distance < ratio*n.distance:\n",
    "            good_points.append(m)\n",
    "  #print(len(good_points))\n",
    "    fin=len(kp_1) -len(kp_2)\n",
    "    print(abs(fin))\n",
    "    if(abs(fin)<=2):\n",
    "        return 'space'\n",
    "    \n",
    "  result = cv2.drawMatches(original, kp_1, image_to_compare, kp_2, good_points, None)\n",
    "   \n",
    "  #cv2.imshow(\"result\", result)\n",
    "  #cv2.imshow(\"Original\", original)\n",
    "  #cv2.imshow(\"Duplicate\", image_to_compare)\n",
    "  #cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor():\n",
    "        import numpy as np\n",
    "        from keras.preprocessing import image\n",
    "        test_image = image.load_img('1.png', target_size=(64, 64))\n",
    "        test_image = image.img_to_array(test_image)\n",
    "        test_image = np.expand_dims(test_image, axis = 0)\n",
    "        result = classifier.predict(test_image)\n",
    "        for i in range(len(fileEntry)):\n",
    "            image_to_compare = cv2.imread(\"./SampleGestures/\"+fileEntry[i])\n",
    "            original = cv2.imread(\"1.png\")\n",
    "            sift = cv2.xfeatures2d.SIFT_create()\n",
    "            kp_1, desc_1 = sift.detectAndCompute(original, None)\n",
    "            kp_2, desc_2 = sift.detectAndCompute(image_to_compare, None)\n",
    "\n",
    "            index_params = dict(algorithm=0, trees=5)\n",
    "            search_params = dict()\n",
    "            flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "            matches = flann.knnMatch(desc_1, desc_2, k=2)\n",
    "\n",
    "            good_points = []\n",
    "            ratio = 0.6\n",
    "            for m, n in matches:\n",
    "                  if m.distance < ratio*n.distance:\n",
    "                         good_points.append(m)\n",
    "            print(fileEntry[i])\n",
    "            if(abs(len(good_points)+len(matches))>20):\n",
    "                gesname=fileEntry[i]\n",
    "                gesname=gesname.replace('.png','')\n",
    "                return gesname\n",
    "       #print(good_points)\n",
    "       #if(abs(fin)<=2):\n",
    "             # return 'space'\n",
    "        if result[0][0] == 1:\n",
    "              return 'A'\n",
    "        elif result[0][1] == 1:\n",
    "              return 'B'\n",
    "        elif result[0][2] == 1:\n",
    "              return 'C'\n",
    "        elif result[0][3] == 1:\n",
    "              return 'D'\n",
    "        elif result[0][4] == 1:\n",
    "              return 'E'\n",
    "        elif result[0][5] == 1:\n",
    "              return 'F'\n",
    "        elif result[0][6] == 1:\n",
    "              return 'G'\n",
    "        elif result[0][7] == 1:\n",
    "              return 'H'\n",
    "        elif result[0][8] == 1:\n",
    "              return 'I'\n",
    "        elif result[0][9] == 1:\n",
    "              return 'J'\n",
    "        elif result[0][10] == 1:\n",
    "              return 'K'\n",
    "        elif result[0][11] == 1:\n",
    "              return 'L'\n",
    "        elif result[0][12] == 1:\n",
    "              return 'M'\n",
    "        elif result[0][13] == 1:\n",
    "              return 'N'\n",
    "        elif result[0][14] == 1:\n",
    "              return 'O'\n",
    "        elif result[0][15] == 1:\n",
    "              return 'P'\n",
    "        elif result[0][16] == 1:\n",
    "              return 'Q'\n",
    "        elif result[0][17] == 1:\n",
    "              return 'R'\n",
    "        elif result[0][18] == 1:\n",
    "              return 'S'\n",
    "        elif result[0][19] == 1:\n",
    "              return 'T'\n",
    "        elif result[0][20] == 1:\n",
    "              return 'U'\n",
    "        elif result[0][21] == 1:\n",
    "              return 'V'\n",
    "        elif result[0][22] == 1:\n",
    "              return 'W'\n",
    "        elif result[0][23] == 1:\n",
    "              return 'X'\n",
    "        elif result[0][24] == 1:\n",
    "              return 'Y'\n",
    "        elif result[0][25] == 1:\n",
    "              return 'Z'\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow(\"Trackbars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.createTrackbar(\"L - H\", \"Trackbars\", 0, 179, nothing)\n",
    "cv2.createTrackbar(\"L - S\", \"Trackbars\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"L - V\", \"Trackbars\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"U - H\", \"Trackbars\", 179, 179, nothing)\n",
    "cv2.createTrackbar(\"U - S\", \"Trackbars\", 255, 255, nothing)\n",
    "cv2.createTrackbar(\"U - V\", \"Trackbars\", 255, 255, nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow(\"ASL Recognition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_text = ''\n",
    "img_text1 = ''\n",
    "#z5=1\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    frame = cv2.flip(frame,1)\n",
    "    l_h = cv2.getTrackbarPos(\"L - H\", \"Trackbars\")\n",
    "    l_s = cv2.getTrackbarPos(\"L - S\", \"Trackbars\")\n",
    "    l_v = cv2.getTrackbarPos(\"L - V\", \"Trackbars\")\n",
    "    u_h = cv2.getTrackbarPos(\"U - H\", \"Trackbars\")\n",
    "    u_s = cv2.getTrackbarPos(\"U - S\", \"Trackbars\")\n",
    "    u_v = cv2.getTrackbarPos(\"U - V\", \"Trackbars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    img = cv2.rectangle(frame, (425,100),(625,300), (0,255,0), thickness=2, lineType=8, shift=0)\n",
    "    lower_blue = np.array([l_h, l_s, l_v])\n",
    "    upper_blue = np.array([u_h, u_s, u_v])\n",
    "    imcrop = img[102:298, 427:623]\n",
    "    hsv = cv2.cvtColor(imcrop, cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "    \n",
    "    cv2.putText(frame, img_text, (30, 400), cv2.FONT_HERSHEY_TRIPLEX, 1.5, (0, 255, 0))\n",
    "    cv2.putText(frame, img_text1, (80, 400), cv2.FONT_HERSHEY_TRIPLEX, 1.5, (0, 255, 0))\n",
    "    cv2.imshow(\"ASL Recognition\", frame)\n",
    "    cv2.imshow(\"mask\", mask)\n",
    "        \n",
    "    img_name = \"1.png\"\n",
    "    save_img = cv2.resize(mask, (image_x, image_y))\n",
    "    cv2.imwrite(img_name, save_img)\n",
    "    img_text = predictor()\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   # img_text1 = imgprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
